[
  {
    "objectID": "ch3.html#measures-of-center",
    "href": "ch3.html#measures-of-center",
    "title": "3  Describing, Exploring, and Comparing Data",
    "section": "3.1 Measures of center",
    "text": "3.1 Measures of center\nMeasures of center, such as the mean and median, provide a central value that summarizes a dataset, helping to understand its typical or central tendency, which is crucial for making data-driven decisions and drawing inferences.\n\n3.1.1 Mean\nThe mean, also known as the average, is a measure of center in a dataset that calculates the sum of all values divided by the total number of values, providing a representative value for the dataset. We will employ the R command mean() to calculate the mean of several datasets. First, let’s use the test scores from Section 2.1.1 which should be stored in scores.\n\n\nCode\n# Load test data into a variable names scores\nscores &lt;- c(95, 90, 85, 85, 87, 74, 75, 64, 85, 84, 87, 15, 20, 75, 75, 90, 75)\n# Calculate mean of scores and then store it in the variable meanScore\nmeanScore &lt;- mean(scores)\n\n# print out the answer\ncat(\"Mean test score is: \", meanScore, \"\\n\")\n\n\nMean test score is:  74.17647 \n\n\nThe mean is very sensitive to outliers. Let’s see what happens when we take the same scores list and add some really low grades to the list.\n\n\nCode\n# Previous test scores with a several much lower scores added\nscores2 &lt;- c(95, 90, 85, 85, 87, 74, 75, 64, 85, 84, 87, 15, 20, 75, 75, 90, 75, 2, 1, 5, 3)\n\n# Calculate mean of scores2 and then store it in the variable meanScore2\nmeanScore2 &lt;- mean(scores2)\n\n# print out the answer\ncat(\"Mean test score is from original is: \", meanScore, \", while from scores2 is: \", meanScore2)\n\n\nMean test score is from original is:  74.17647 , while from scores2 is:  60.57143\n\n\nThis sensitivity to outliers is the notion of resistance. The mean is not a resistant measure of middle.\n\n\n3.1.2 Median\nThe median is a measure of center in a dataset that represents the middle value when all values are ordered, and it is resistant to extreme outliers, making it a robust statistic for summarizing data. Let’s return to the scores data and see the difference between mean and median of the two datasets scores and scores2 using the R commands median().\n\n\nCode\n# Calculate median of scores and then store it in the variable medianScore\nmedianScore &lt;- median(scores)\n\n# Calculate median of scores2 and then store it in the variable medianScore2\nmedianScore2 &lt;- median(scores2)\n\n# print out the answer\ncat(\"Mean test score from original is: \", meanScore, \", while from scores2 is: \", meanScore2, \"\\n\\n\")\n\n\nMean test score from original is:  74.17647 , while from scores2 is:  60.57143 \n\n\nCode\ncat(\"Median test score from original is: \", medianScore, \", while from scores2 is: \", medianScore2, \"\\n\")\n\n\nMedian test score from original is:  84 , while from scores2 is:  75 \n\n\n\n\n3.1.3 Mode\nThe mode is a statistical measure that represents the value or values that occur most frequently in a dataset, making it a useful indicator of the most common observation(s); however, it is not necessarily resistant to outliers, meaning extreme values can heavily influence the mode. There is no bulit-in R command for mode, so we will have to employ the package DescTools.\nThe first time you run this code, you will need to install the following package. After this initial run, you can skip running this code:\n\n\nCode\n# Installs the package 'DescTools'.  ONLY RUN THIS CODE ONCE!\ninstall.packages('DescTools')\n\n\nOnce this package is installed, then we can load the library DescTools in order to use the R command Mode().\n\n\nCode\n# Load the DescTools package\nlibrary(DescTools)\n\n\nWarning: package 'DescTools' was built under R version 4.2.3\n\n\nCode\n# Calculate the mode of both scores and scores2 using the Mode() method\n\n# Calculate Mode of scores and then store it in the variable modeScore\nmodeScore &lt;- Mode(scores)\n\n# Calculate median of scores2 and then store it in the variable modeScore2\nmodeScore2 &lt;- Mode(scores2)\n\n# print out the answer\ncat(\"Mode test score from original is: \", modeScore, \", while from scores2 is: \", modeScore2, \"\\n\")\n\n\nMode test score from original is:  75 , while from scores2 is:  75 \n\n\n\n\n3.1.4 Midrange\nThe midrange is a measure of center in a dataset that represents the arithmetic mean of the maximum and minimum values, and it is not resistant to extreme outliers, making it sensitive to extreme values. There is no built-in R command for midrange, thus we will use the following code to calculate the midrange of our scores and scores2 data.\n\n\nCode\n# Calculate miderange of scores and then store it in the variable midrangeScore\nmidrangeScore &lt;- (max(scores) - min(scores)) / 2\n\n# Calculate midrange of scores2 and then store it in the variable midrangeScore2\nmidrangeScore2 &lt;- (max(scores2) - min(scores2)) / 2\n\n# print out the answer\ncat(\"Midrange test score from original is: \", midrangeScore, \", while from scores2 is: \", midrangeScore2, \"\\n\")\n\n\nMidrange test score from original is:  40 , while from scores2 is:  47 \n\n\n\n\n3.1.5 Let’s put it all togeher!\nConsider the built-in dataset mtcars which contains several aspects and performance of several 1973 - 1974 model cars which we studied in Section 2.4. We will calculate mean, meidan, mode, and midrange of the miles per gallon of tthe cars in the dataset. using the R commands illustrated in the previous sections, as well as compute the so-called 5-number summary using the R command summary(). First, let’s plot a histogram of the data.\n\n\nCode\n# Extract the MPG data and store it into the variable carsMPG\ncarsMPG &lt;- mtcars$mpg\n\n# Generate a histogram of the MPG data from mtcars\nhist(carsMPG, main = \"MPG for cars\", xlab = \"MPG\")\n\n\n\n\n\nCode\n# Calculate mean of MPG data and then store it in the variable meanMPG\nmeanMPG &lt;- round(mean(carsMPG), digits = 2)\n\n# Calculate median of MPG data and then store it in the variable medianMPG\nmedianMPG &lt;- median(carsMPG)\n\n# Calculate Mode of scores and then store it in the variable modeMPG\nmodeMPG &lt;- Mode(carsMPG)\n\n# Calculate miderange of scores and then store it in the variable midrangeMPG\nmidrangeMPG &lt;- (max(carsMPG) - min(carsMPG)) / 2\n\n# print out the answer\ncat(\"Mean \\t Median \\t \\t \\t  Mode \\t \\t \\t Midrange \\n\")\n\n\nMean     Median               Mode           Midrange \n\n\nCode\ncat(meanMPG, \" \\t \", medianMPG, \" \\t \", modeMPG, \" \\t \", midrangeMPG, \"\\n\\n\")\n\n\n20.09     19.2        10.4 15.2 19.2 21 21.4 22.8 30.4        11.75 \n\n\nCode\n# Give the 5-number summary for MPG data\ncat(\"5-Number Summary \\n\")\n\n\n5-Number Summary \n\n\nCode\nsummary(carsMPG)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.40   15.43   19.20   20.09   22.80   33.90 \n\n\nNotice that there are 7 elements in the mode. That’s because there are 7 most frequent elements, each which appear twice. Which of these central measures best describes what you visually see as the “center” of data using the histogram? What does it “mean” that the mean and median are close to each other? Does the 5-number summary give us any additional information regarding the measure of “center” in the data?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Describing, Exploring, and Comparing Data</span>"
    ]
  },
  {
    "objectID": "ch3.html#measures-of-variation",
    "href": "ch3.html#measures-of-variation",
    "title": "3  Describing, Exploring, and Comparing Data",
    "section": "3.2 Measures of variation",
    "text": "3.2 Measures of variation\nMeasures of variation, such as the range, variance, and standard deviation, provide insights into the spread or dispersion of data points within a dataset, helping us understand how much individual values deviate from the central tendency measures like the mean or median. These measures are essential because they quantify the degree of variability in data, allowing us to assess data quality, make more accurate predictions, and draw meaningful conclusions in statistical analysis.\n\n3.2.1 Visualizing variation\nHistograms can visually represent the variation in a dataset by displaying the distribution of values across different bins or intervals, highlighting the frequency and pattern of data points, and revealing the shape and spread of the distribution. Let’s compare histograms for our scores2 and carsMPG datasets.\n\n\nCode\n# Generate a histogram of the MPG data from scores2\nhist(scores2, main = \"Test scores\", xlab = \"Score\")\n\n\n\n\n\nCode\n# Generate a histogram of the MPG data from mtcars\nhist(carsMPG, main = \"MPG for cars\", xlab = \"MPG\")\n\n\n\n\n\n\n\n3.2.2 Range\nThe range is a measure of variation that represents the difference between the maximum and minimum values in a dataset, but it is not resistant to outliers, meaning extreme values can substantially affect the range. Let’s compare the ranges of our carsMPG and scores2 datasets using the R command range().\n\n\nCode\n# Calculate range of scores2 and then store it in the variable rangeScore2\nrangeScore2 &lt;- range(scores2)\n\n# Calculate range of carsMPG and then store it in the variable rangeMPG\nrangeMPG &lt;- range(carsMPG)\n\n# print out the answer\ncat(\"Range for test scores from scores2 is: (\", rangeScore2[1], \", \",rangeScore2[2], \") \\n\")\n\n\nRange for test scores from scores2 is: ( 1 ,  95 ) \n\n\nCode\ncat(\"Range for MPG from carsMPG is: (\", rangeMPG[1], \", \", rangeMPG[2], \") \\n\")\n\n\nRange for MPG from carsMPG is: ( 10.4 ,  33.9 ) \n\n\n\n\n3.2.3 Standard deviation\nStandard deviation is a measure of the dispersion or spread of data points in a dataset, with a higher value indicating greater variability, and it’s calculated differently for populations (\\sigma) and samples (s), where the sample standard deviation (s) is often used for practical data analysis. However, standard deviation is not resistant to extreme outliers, making it sensitive to the influence of extreme values on its magnitude. There is a built-in R command for sample standard deviation, but no such command for population standard deviation. Recall our test scores dataset scores2. Since this data represents the entire population (every student in the class), we will calculate population standard deviation for that dataset. However, the MPG data in carsMPG is only a sample of all the cars on the market in 1973 - 1974. Thus, we will employ the R command sd() to calculate sample standard deviation.\n\n\nCode\n# Calculate population SD of scores2 and then store it in the variable popSDScore2\npopSDScore2 &lt;- sqrt(var(scores2) * (length(scores2) - 1) / length(scores2))\n\n# Calculate sample SD of carsMPG and then store it in the variable samSDMPG\nsamSDMPG &lt;- sd(carsMPG)\n\n# Print out the answer\ncat(\"Population standard deviation for test scores from scores2 is: \", popSDScore2, \"\\n\\n\")\n\n\nPopulation standard deviation for test scores from scores2 is:  34.35331 \n\n\nCode\ncat(\"Sample standard deviation for MPG from carsMPG is: \", samSDMPG, \" \\n\")\n\n\nSample standard deviation for MPG from carsMPG is:  6.026948  \n\n\n\n\n3.2.4 Variance\nVariance measures the average of the squared differences between each data point and the mean of a dataset, providing a measure of data dispersion, but it is not resistant to extreme outliers, making it sensitive to the influence of extreme values on its magnitude. Variance is calculated differently for populations (\\sigma^2) and samples (s^2), with the sample variance (s^2) being used for practical data analysis to account for bias when working with a subset of a larger population. Let’s compare population variance for our scores2 dataset and sample variance for our carsMPG dataset. As with standard deviation, although there is a built-in R command for sample variance, there is not a built-in command for population variance, so we will have to improvise.\n\n\nCode\n# Calculate population variance of scores2 and then store it in the variable popVarScore2\npopVarScore2 &lt;- var(scores2) * (length(scores2) - 1) / length(scores2)\n\n# Calculate sample variance of carsMPG and then store it in the variable samSDMPG\nsamVarMPG &lt;- var(carsMPG)\n\n# Print out the answer\ncat(\"Population variance for test scores from scores2 is: \", popVarScore2, \"\\n\\n\")\n\n\nPopulation variance for test scores from scores2 is:  1180.15 \n\n\nCode\ncat(\"Sample variance for MPG from carsMPG is: \", samVarMPG, \" \\n\")\n\n\nSample variance for MPG from carsMPG is:  36.3241  \n\n\n\n\n3.2.5 Let’s put it all togeher!\nConsider the built-in dataset mtcars which contains several aspects and performance of several 1973 - 1974 model cars which we studied in Section 2.4. We will first calculate mean and median of the horse power (HP) of the cars in the dataset. To calculate measures of variation, we note that since this is just a sample of all possible cars on the market during 1973 - 1974, we will employ sample variance and standard deviation using the R commands illustrated in the previous sections, along with a histogram to visually explore the data.\n\n\nCode\n# Extract the HP data and store it into the variable carsHP\ncarsHP &lt;- mtcars$hp\n\n# Generate a histogram of the HP data from mtcars\nhist(carsHP, main = \"Horse power (HP) for cars\", xlab = \"HP\")\n\n\n\n\n\nCode\n# Calculate mean of HP data and then store it in the variable meanHP\nmeanHP &lt;- round(mean(carsHP), digits = 2)\n\n# Calculate median of HP data and then store it in the variable medianHP\nmedianHP &lt;- median(carsHP)\n\n# Calculate variance of HP data and then store it in the variable varHP\nvarHP &lt;- var(carsHP)\n\n# Calculate standard deviation of HP and then store it in the variable midrangeHP\nsdHP &lt;- sd(carsHP)\n\n# print out the answer\ncat(\"Mean \\t Median \\t  variance \\t Standard Deviation \\n\")\n\n\nMean     Median       variance   Standard Deviation \n\n\nCode\ncat(meanHP, \" \\t \", medianHP, \" \\t \", varHP, \" \\t \", sdHP, \"\\n\\n\")\n\n\n146.69        123     4700.867        68.56287 \n\n\nNow, compare the MPG and HP data from the mtcars dataset. For MPG, we calculated a standard deviation around 36 and for HP of around 69. Does this mean that the MPG data is less spread out that the HP data? Is your answer to this question consistent with the histograms we produced? Can we compare standard deviations from two totally different datasets in a meaningful way?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Describing, Exploring, and Comparing Data</span>"
    ]
  },
  {
    "objectID": "ch3.html#measures-of-relative-standing-and-boxplots",
    "href": "ch3.html#measures-of-relative-standing-and-boxplots",
    "title": "3  Describing, Exploring, and Comparing Data",
    "section": "3.3 Measures of relative standing and boxplots",
    "text": "3.3 Measures of relative standing and boxplots\nMeasures of relative standing, such as percentiles and quartiles, provide information about where specific data points fall within a dataset, offering insights into the relative position of values. Boxplots are graphical representations that display the distribution of data, highlighting the median, quartiles, and potential outliers, making them valuable tools for comparing different datasets by visually assessing their central tendency, spread, and skewness.\n\n3.3.1 z-Scores\nZ-scores, also known as standard scores, standardize individual data points by expressing how many standard deviations they are from the mean, enabling meaningful comparisons and assessments of data points’ relative positions within a distribution, regardless of the original scale of the data. Z-scores are valuable for identifying outliers, understanding data distributions, and making statistical inferences, as they provide a common framework for measuring deviations from the mean across different datasets. Let’s explore z-scores using the built-in dataset mtcars which contains several aspects and performance of several 1973 - 1974 model cars which we studied in the last section. Particularly, let’s employ the built-in R command scale() to convert our dataset to z-scores which can be plotted in a histogram. Once the two datasets (MPG and HP) are normalized, we will be able to get a better picture of their spread away from the respective means.\n\n\nCode\n# Transform the MPG data to z-scores and store the new data in zcarsHP\nzcarsHP &lt;- scale(carsHP)\n\n# Transform the MPG data to z-scores and store the new data in zcarsHP\nzcarsMPG &lt;- scale(carsMPG)\n\n# Generate a histogram of the transformed HP data from mtcars\nhist(zcarsHP, main = \"Normalized horse power (HP) for cars\", xlab = \"Z-score\")\n\n\n\n\n\nCode\n# Generate a histogram of the transformed MPG data from mtcars\nhist(zcarsMPG, main = \"Normalized miles per gallon (MPG) for cars\", xlab = \"Z-score\")\n\n\n\n\n\nVisually, the normalized MPG data is more concentrated around the transformed mean of 0, while the HP data is much more spread out.\nAny data point that has a z-score of less than -2 or higher than 2 is considered to be significantly lower or higher, respectively. Let’s view our transformed data sets MPG and HP to identify data points that are significantly higher.\n\n\nCode\n# Find MPG data points with z-scores higher than 2\noutliersMPG &lt;- carsMPG[zcarsMPG &gt; 2]\n\n# Find HP data points with z-scores higher than 2\noutliersHP &lt;- carsHP[zcarsHP &gt; 2]\n\n# Print the data points with z-scores higher than 2\ncat(\"MPG Data with z-scores higher than 2:\", outliersMPG, \"\\n\")\n\n\nMPG Data with z-scores higher than 2: 32.4 33.9 \n\n\nCode\ncat(\"HP Data with z-scores higher than 2:\", outliersHP, \"\\n\")\n\n\nHP Data with z-scores higher than 2: 335 \n\n\n\n\n3.3.2 Percentiles\nPercentiles are statistical measures that divide a dataset into 100 equal parts, helping identify values below which a certain percentage of the data falls and enabling comparisons of data points in a ranked order. Let’s use the built-in R command quantile()with the MPG data from the previous example to compute the 10th, 50th, and 90th percentiles for that dataset.\n\n\nCode\n# Compute 10th, 50th, and 90th percentiles for the MPG dataset\npercentiles &lt;- c(0.1, 0.5, 0.9)\npercentilesMPG &lt;- quantile(carsMPG, probs = percentiles)\n\n# Print the data points with z-scores higher than 2\npercentilesMPG\n\n\n  10%   50%   90% \n14.34 19.20 30.09 \n\n\nNotice that both of our significantly larger MPG values (i.e., 32.4 and 33.9) both fall above the 90th percentile of the dataset.\n\n\n3.3.3 Quartiles & the 5-number summary\nQuartiles are statistical measures that divide a dataset into four equal parts, with three quartiles (Q1, Q2, Q3) providing insights into the data’s spread and central tendencies; they are resistant to outliers, making them robust tools for summarizing data. The 5-number summary is a set of five statistics (minimum, Q1, median, Q3, maximum) that provide a concise description of a dataset’s central tendencies and spread. Keeping with our MPG dataset, we will employ the R command summary() to give the 5-number summary (which will include Q1, Q2 (also known as the median), & Q3).\n\n\nCode\n# Compute 5-number summary for MPG data and store it in fiveMPG\nfiveMPG &lt;- summary(carsMPG)\n\n# Display the 5-number summary\nfiveMPG\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.40   15.43   19.20   20.09   22.80   33.90 \n\n\n\n\n3.3.4 Boxplot\nA boxplot, also known as a box-and-whisker plot, is a graphical representation of the five-number summary, displaying the median, quartiles, and potential outliers in a dataset, making it a valuable tool for visualizing the distribution and spread of data. We will employ the R command boxplot() to compare the MPG and HP datasets from previous examples. This R command actually creates a modified boxplot by default. Recall the only difference between a regular boxplot and a modified box plot is that data which falls outside of the interquartile range is denoted as an outlier and plotted as an individual point on the graph.\n\n\nCode\n# Generate boxplot for MPG\nboxplot(carsMPG, main = \"Boxplot of MPG\", horizontal = TRUE, xlab = \"MPG\")\n\n\n\n\n\nCode\n# Generate boxplot for HP\nboxplot(carsHP, main = \"Boxplot of HP\", horizontal = TRUE, xlab = \"HP\")\n\n\n\n\n\nLet’s also compare the boxplots of each of the four datasets for which we explored normal, skewed right, skewed left, and uniform distributions.\n\n\nCode\n# Create histogram/boxplot of normal data\n# Sample normal distribution\nnormalData &lt;- rnorm(100)\npar(mfrow = c(2,1))\nhist(normalData, main = \"Normal distribution\")\nboxplot(normalData, main = \"Normal Distribution\", horizontal = TRUE)\n\n\n\n\n\nCode\n# Create histogram/boxplot of uniform data\n# Sample uniform distribution using the command runif\nuniformData &lt;- runif(50000, min = 10, max = 11)\npar(mfrow = c(2,1))\nhist(uniformData, main = \"Uniform distribution\")\nboxplot(uniformData, main = \"Uniform Distribution\", horizontal = TRUE)\n\n\n\n\n\nCode\n# Sample of a distribution that is skewed right\nskewedRightData &lt;- rexp(1000, 0.4)\n# Create histogram/boxplot of skewed right data\npar(mfrow = c(2,1))\nhist(skewedRightData, main = \"Distribution that is skewed right\")\nboxplot(skewedRightData, main = \"Distribution that is skewed right\", horizontal = TRUE)\n\n\n\n\n\nCode\n# Sample of a distribution that is skewed left\nskewedLeftData &lt;- 1 - rexp(1000, 0.2)\n# Create histogram/boxplot of skewed left data\npar(mfrow = c(2,1))\nhist(skewedLeftData, main = \"Distribution that is skewed left\")\nboxplot(skewedLeftData, main = \"Distribution that is skewed left\", horizontal = TRUE)\n\n\n\n\n\nNotice there are a lot of outliers shown on the skewed left & right data. These points are what is causing the long tails on both histograms.\n\n\n3.3.5 Let’s put it all together!\nWe will use everything we have learned so far in this section to explore the differences between our two test score datasets, i.e., scores and scores2. These are fictional collections of test scores with scores2 containing several more extremely low test scores than scores. Our first task is to transform the datasets to z-scores and visualize the scaled datasets with a histrogram.\n\n\nCode\n# Transform the scores data to z-scores and store the new data in zscores\nzscores &lt;- scale(scores)\n\n# Transform the scorres2 data to z-scores and store the new data in zscores2\nzscores2 &lt;- scale(scores2)\n\n# Generate a histogram of the transformed from scores\nhist(zscores, main = \"Normalized test scores #1\", xlab = \"Z-score\")\n\n\n\n\n\nCode\n# Generate a histogram of the transformed from scores2\nhist(zscores2, main = \"Normalized test scores #2\", xlab = \"Z-score\")\n\n\n\n\n\nOut of the two fictional classes, are there any test scores that are significantly high or low? What can we conclude about those scores? Now, let’s compute the 5-number summary for each group of test scores.\n\n\nCode\n# Compute 5-number summary for scores\ncat(\"scores: \\n \\n\")\n\n\nscores: \n \n\n\nCode\nsummary(scores)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  15.00   75.00   84.00   74.18   87.00   95.00 \n\n\nCode\n# Compute 5-number summary for scores2\ncat(\"\\nscores2: \\n \\n\")\n\n\n\nscores2: \n \n\n\nCode\nsummary(scores2)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00   20.00   75.00   60.57   85.00   95.00 \n\n\nFinally, let’s create boxplots for both datasets and show them on the same plot window for comparison.\n\n\nCode\n# Generate boxplot for both\npar(mfrow = c(2,1))\nboxplot(scores, main = \"Boxplot of test scores #1\", horizontal = TRUE, xlab = \"Scores\")\nboxplot(scores2, main = \"Boxplot of test scores #2\", horizontal = TRUE, xlab = \"Scores\")\n\n\n\n\n\nWhat conclusions can we draw regarding the two datasets? If these were two real classes, how would the boxplots help the teacher understand grade performance for the entire class?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Describing, Exploring, and Comparing Data</span>"
    ]
  }
]